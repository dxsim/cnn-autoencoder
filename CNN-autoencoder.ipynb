{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.__version__\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input,Dense,Activation,BatchNormalization,Flatten,Conv2D,MaxPooling2D,UpSampling2D\n",
    "from keras.layers import MaxPooling2D, Dropout, UpSampling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import pandas as pd\n",
    "import os\n",
    "from annoy import AnnoyIndex\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for dirs\n",
    "import os\n",
    "train_dir = './data/train_transformed/'\n",
    "test_dir = './data/test_transformed/'\n",
    "model_dir = './models/'\n",
    "log_dir = './logs/'\n",
    "test_batch_dir = './data/test_results'\n",
    "for dir in [train_dir,test_dir,model_dir,log_dir, test_batch_dir]:\n",
    "    if not(os.path.exists(dir)):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading info from parser\n",
    "\n",
    "info = {\n",
    "    \"inputShape\": (200,200,1),\n",
    "    \"autoencoderFile\": os.path.join(model_dir, \"autoencoder.h5\"), \n",
    "    \"encoderFile\": os.path.join(model_dir, \"encoder.h5\"),\n",
    "    \"decoderFile\": os.path.join(model_dir, \"decoder.h5\"),\n",
    "    \"checkpointFile\": os.path.join(model_dir, \"checkpoint.h5\"),\n",
    "    \"trainHistory\": os.path.join(model_dir, \"train_history.csv\"),\n",
    "    \"mode\": 'train',\n",
    "    \"retrain\": True,\n",
    "    \"loss\": 'mse',\n",
    "    \"optimizer\": 'adam',\n",
    "    \"batchSize\": 32,\n",
    "    \"multiprocessing\": True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set generation\n",
    "test_datagen = image.ImageDataGenerator(rescale=1./255,\n",
    "                                     rotation_range=90,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     zoom_range=0.2)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                test_dir,\n",
    "                target_size=info[\"inputShape\"][:2],\n",
    "                batch_size=1,\n",
    "                color_mode='grayscale',\n",
    "                class_mode='input',\n",
    "                seed=0\n",
    "                        )\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set generation (80-20 split)\n",
    "train_datagen = image.ImageDataGenerator(rescale=1./255,\n",
    "                                    validation_split=0.2,\n",
    "                                    rotation_range=20,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    horizontal_flip=False,\n",
    "                                    vertical_flip=False\n",
    "                                  )\n",
    "# For training (train-validation)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=info[\"inputShape\"][:2],\n",
    "    batch_size=info[\"batchSize\"],\n",
    "    color_mode='grayscale',\n",
    "    class_mode='input',\n",
    "    subset='training',\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=info[\"inputShape\"][:2],\n",
    "    batch_size=info[\"batchSize\"],\n",
    "    color_mode='grayscale',\n",
    "    class_mode='input',\n",
    "    subset='validation',\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder():\n",
    "    \n",
    "    def __init__(self, info):\n",
    "        self.info= info\n",
    "\n",
    "    \n",
    "    def build_models(self):\n",
    "        \n",
    "        # Build and compile\n",
    "        # Print building models\n",
    "        conv_shape = (3,3) # convolutional kernel shape\n",
    "        pool_shape = (2,2) # pooling kernel shape\n",
    "        n_hidden_1, n_hidden_2, n_hidden_3 = 16, 8, 8 # channel numbers\n",
    "        input_shape = self.info['inputShape']\n",
    "        input_layer = Input(shape= input_shape)\n",
    "        \n",
    "        #encoder layers\n",
    "        x = Conv2D(n_hidden_1, conv_shape, activation='relu', padding='same')(input_layer)\n",
    "        x = MaxPooling2D(pool_shape, padding='same')(x)\n",
    "        x = Conv2D(n_hidden_2, conv_shape, activation='relu', padding='same')(x)\n",
    "        x = MaxPooling2D(pool_shape, padding='same')(x)\n",
    "        x = Conv2D(n_hidden_3, conv_shape, activation='relu', padding='same')(x)\n",
    "        encoded = MaxPooling2D(pool_shape, padding='same')(x)\n",
    "        \n",
    "        #decoded layers\n",
    "        x = Conv2D(n_hidden_3, conv_shape, activation='relu', padding='same')(encoded)\n",
    "        x = UpSampling2D(pool_shape)(x)\n",
    "        x = Conv2D(n_hidden_2, conv_shape, activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D(pool_shape)(x)\n",
    "        x = Conv2D(n_hidden_1, conv_shape, activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D(pool_shape)(x)\n",
    "        decoded = Conv2D(input_shape[2], conv_shape, activation='sigmoid', padding='same')(x)\n",
    "        \n",
    "        # Creating Autoencoder\n",
    "        autoencoder = Model(input_layer,decoded)\n",
    "        # Creating Encoder\n",
    "        encoder = Model(input_layer,encoded)\n",
    "        \n",
    "        # Output encoder shapes\n",
    "        output_encoder_shape = encoder.layers[-1].output_shape[1:]\n",
    "\n",
    "        # Create decoder model (Reverse)\n",
    "        decoded_input = Input(shape=output_encoder_shape)\n",
    "        \n",
    "        decoded_output = autoencoder.layers[-7](decoded_input)  # Conv2D\n",
    "        decoded_output = autoencoder.layers[-6](decoded_output)  # UpSampling2D\n",
    "        decoded_output = autoencoder.layers[-5](decoded_output)  # Conv2D\n",
    "        decoded_output = autoencoder.layers[-4](decoded_output)  # UpSampling2D\n",
    "        decoded_output = autoencoder.layers[-3](decoded_output)  # Conv2D\n",
    "        decoded_output = autoencoder.layers[-2](decoded_output)  # UpSampling2D\n",
    "        decoded_output = autoencoder.layers[-1](decoded_output)  # Conv2D\n",
    "        \n",
    "        decoder = Model(decoded_input, decoded_output)\n",
    "        \n",
    "        # Generate summaries\n",
    "        print(\"\\nautoencoder.summary():\")\n",
    "        print(autoencoder.summary())\n",
    "        print(\"\\nencoder.summary():\")\n",
    "        print(encoder.summary())\n",
    "        print(\"\\ndecoder.summary():\")\n",
    "        print(decoder.summary())\n",
    "        \n",
    "        self.autoencoder = autoencoder\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        print('Models succesfully built')\n",
    "        \n",
    "        self.compile(loss = self.info['loss'], optimizer = self.info['optimizer'])\n",
    "        \n",
    "        print('Building and compilation done')\n",
    "        \n",
    "    def compile(self, loss='binary_crossentropy', optimizer='adam'):\n",
    "        print('Compiling models...')\n",
    "        # To fit the model using the parameters\n",
    "        self.autoencoder.compile(loss=loss,optimizer=optimizer)\n",
    "    \n",
    "    def predict_embedding(self,test_generator, steps):\n",
    "        return self.encoder.predict_generator(test_generator, steps)\n",
    "    \n",
    "    def reconstruct_img(self,X):\n",
    "        return self.autoencoder.predict(X)\n",
    "    \n",
    "    def predict_generator(self, test_generator, steps):\n",
    "        return self.autoencoder.predict_generator(test_generator, steps)\n",
    "    \n",
    "    def fit(self, train_generator, validation_generator, n_epochs=2, batch_size=256, callbacks=[]): \n",
    "        # Split the train test set\n",
    "        print('Fitting models....')\n",
    "\n",
    "        self.autoencoder.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = train_generator.samples // batch_size,\n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = validation_generator.samples // batch_size,\n",
    "                    verbose=1,\n",
    "                    epochs = n_epochs,\n",
    "                    use_multiprocessing=self.info[\"multiprocessing\"],\n",
    "                    callbacks=callbacks,\n",
    "                    max_queue_size=16,\n",
    "                    workers=8,\n",
    "        )\n",
    "    \n",
    "    def save_models(self):\n",
    "        print('Saving models...')\n",
    "        self.autoencoder.save(self.info[\"autoencoderFile\"])\n",
    "        self.encoder.save(self.info[\"encoderFile\"])\n",
    "        self.decoder.save(self.info[\"decoderFile\"])\n",
    "        \n",
    "        print('models.saved')\n",
    "        \n",
    "    def load_models(self, loss='mse', optimizer='adam'):\n",
    "        print('Loading and compiling models..')\n",
    "        self.autoencoder = load_model(self.info[\"autoencoderFile\"]) #compile=False for this laptop\n",
    "        self.encoder = load_model(self.info[\"encoderFile\"])\n",
    "        self.decoder = load_model(self.info[\"decoderFile\"])\n",
    "        self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "        self.encoder.compile(optimizer=optimizer, loss=loss)\n",
    "        self.decoder.compile(optimizer=optimizer, loss=loss)\n",
    "        \n",
    "        print('Loading and compiling models done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(info)\n",
    "\n",
    "info['retrain']=False # Rebuild model for retraining\n",
    "\n",
    "if info['retrain']:\n",
    "    model.build_models()\n",
    "else:\n",
    "\n",
    "    model.load_models()\n",
    "#     else:\n",
    "#         model.build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "train_history_file = info['trainHistory']\n",
    "checkpoint_file = info['checkpointFile']\n",
    "csv_logger=CSVLogger(train_history_file, append=True, separator=';')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20) \n",
    "checkpoint = ModelCheckpoint(checkpoint_file, monitor='val_loss', verbose=1, save_best_only=True, mode='auto', period=5)\n",
    "# tensorboard = TensorBoard(log_dir=os.path.join(log_dir,str(time()))) # Tensorboard doesn't work with keras release\n",
    "callbacks = [csv_logger,es,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "if info['mode']=='train':\n",
    "    hist = model.fit(train_generator,\n",
    "                     validation_generator, \n",
    "                     n_epochs=200,\n",
    "                     batch_size=32,\n",
    "                     callbacks = callbacks\n",
    "             )\n",
    "    model.save_models() # Save encoder models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_history_file,delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.plot(x='epoch',y=['val_loss','loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAWING VISUALIZATION\n",
    "## Load images from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation for original images\n",
    "orig_datagen = image.ImageDataGenerator(rescale=1./255,)\n",
    "\n",
    "# Generator for original images (# CHANGED TO TRAIN_DIR TEMPORARILY)\n",
    "orig_generator = orig_datagen.flow_from_directory(\n",
    "                train_dir,\n",
    "                target_size=info[\"inputShape\"][:2],\n",
    "                batch_size=1,\n",
    "                color_mode='grayscale',\n",
    "                class_mode='categorical',\n",
    "                seed=0,\n",
    "                shuffle=False\n",
    "                        )\n",
    "\n",
    "label_names = orig_generator.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for loading drawings\n",
    "import math\n",
    "def load_image(p):\n",
    "    img = cv2.imread(p,cv2.IMREAD_GRAYSCALE)\n",
    "    img = img/255.\n",
    "    return img\n",
    "\n",
    "class MySequence(Sequence):\n",
    "    def __init__(self, images_dir, batch_size=1):\n",
    "#       images = glob.glob(images_dir + \"/**/*.jpg\", recursive=True)\n",
    "        images = glob.glob(images_dir + \"/**/*.png\", recursive=True)\n",
    "        print(f\"Found {len(images)} images in {images_dir}\")\n",
    "\n",
    "        self.images = images\n",
    "        self.batch_size = batch_size\n",
    "        self.filenames = images\n",
    "\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.images)/self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get start and end indices for batch\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = (idx + 1) * self.batch_size\n",
    "\n",
    "        batch_images = self.images[start_idx:end_idx]\n",
    "        X = []\n",
    "        img_names = ''\n",
    "        for path in batch_images:\n",
    "            # Load image using cv2\n",
    "            img = load_image(path)\n",
    "\n",
    "            # Resize image using cv2\n",
    "            img = cv2.resize(img, (200, 200))\n",
    "            \n",
    "            img = img.reshape(200,200,1)\n",
    "            X.append(img)\n",
    "            img_name = path\n",
    "\n",
    "        X = np.stack(X, axis=0)\n",
    "\n",
    "        # Return the entire batch of images (you may also return the labels like so: return X, y)\n",
    "        return X, img_name\n",
    "    \n",
    "drawings_dir = './data/drawings/'\n",
    "drawing_generator = MySequence(drawings_dir)\n",
    "draw_labels = drawing_generator.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate embeddings in the dataset\n",
    "original = model.predict_embedding(orig_generator,len(label_names))  \n",
    "original = original.reshape(original.shape[0],-1)\n",
    "\n",
    "# Calculate embeddings for drawings\n",
    "drawing_prob = model.predict_embedding(drawing_generator,len(draw_labels)) \n",
    "drawing_prob = drawing_prob.reshape(drawing_prob.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create annoy indexer \n",
    "def create_annoy(preds, metric, n_trees=1000):\n",
    "    f = 5000\n",
    "#     start = time.time()\n",
    "    \n",
    "    t = AnnoyIndex(f, metric)  # Length of item vector that will be indexed\n",
    "    for i in range(preds.shape[0]):\n",
    "        v = preds[i]\n",
    "        t.add_item(i, v)\n",
    "    \n",
    "    t.build(n_trees)\n",
    "    \n",
    "#     end = time.time()\n",
    "#     print(f'Built annoy {metric} model in {end - start} seconds')\n",
    "    return t\n",
    "\n",
    "def save_annoy(fileName,t):\n",
    "    save_dir = os.path.join(annoy_dir,fileName)\n",
    "    t.save(save_dir)\n",
    "\n",
    "# Load annoy model\n",
    "def load_annoy(fileName,metric='euclidean'):\n",
    "    f = 5000\n",
    "    load_dir = os.path.join(annoy_dir,fileName)\n",
    "    t = AnnoyIndex(f, metric)\n",
    "    t.load(load_dir)\n",
    "    return t\n",
    "\n",
    "# Load an image to the current model\n",
    "def load_img_annoy(t,v,n_trees=1000):\n",
    "    # Unbuild to add drawing\n",
    "    start = time.time()\n",
    "    t.unbuild()\n",
    "    \n",
    "    last_index = t.get_n_items()\n",
    "    t.add_item(last_index, v)\n",
    "    # \n",
    "    t.build(n_trees)\n",
    "    end = time.time()\n",
    "    print(f'Reloaded annoy in {end - start} seconds')\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the annoy index from the full dataset (RUN THIS ONCE)   \n",
    "# Recommend 'euclidean' or 'angular' (closest to cosine)\n",
    "metric = \"euclidean\"\n",
    "annoy_dir = './annoy/'\n",
    "\n",
    "annoy_indexer = create_annoy(original,metric)\n",
    "\n",
    "save_annoy(f'annoy-{metric}.ann',annoy_indexer) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annoy index \n",
    "# annoy_indexer = load_annoy(f'annoy-{metric}_(Drawings).ann', metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pairs =[]\n",
    "\n",
    "plot_names=[]\n",
    "\n",
    "for new_drawing,drawing_name in tqdm(zip(drawing_prob,draw_labels)):\n",
    "    \n",
    "    idx = annoy_indexer.get_nns_by_vector(new_drawing, 8) # will find the nearest neighbors of index 1070\n",
    "    print(idx)\n",
    "    \n",
    "    for i in range(0, 8):\n",
    "        \n",
    "        database_name = label_names[idx[i]] \n",
    "\n",
    "        database_name = os.path.join(train_dir,database_name)\n",
    "        \n",
    "        if i == 0:\n",
    "            plot_names.append(drawing_name)\n",
    "        \n",
    "        plot_names.append(database_name)\n",
    "        \n",
    "\n",
    "print(plot_names)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(25,9,figsize=(40,100))\n",
    "[axi.set_axis_off() for axi in axes.ravel()]\n",
    "\n",
    "for i, (ax,im) in enumerate(zip(axes.flatten(),plot_names)):\n",
    "    img = PIL.Image.open(im)\n",
    "    ax.imshow(img,cmap='gray')\n",
    "\n",
    "plt.subplots_adjust(left=0,right=1,bottom=0,top=1,wspace = 0,hspace = 0)\n",
    "\n",
    "fig.savefig(os.path.join(test_batch_dir,f'drawings_similarity_{metric}.png'),dpi=150)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
